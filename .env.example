# AI Problem Generator Configuration
# Copy this file to .env.local and add your actual API key

# === DeepSeek Configuration (Optional) ===
# DeepSeek API Key for AI problem generation
# Get your API key from: https://platform.deepseek.com/
# DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Optional: Set API timeout (default: 30000ms)
# DEEPSEEK_API_TIMEOUT=30000

# Optional: Set maximum tokens for generation (default: 4000)
# DEEPSEEK_MAX_TOKENS=4000

# === Ollama Configuration (Optional) ===
# Ollama endpoint (default: http://localhost:11434)
# OLLAMA_ENDPOINT=http://localhost:11434

# Ollama model (default: llama3)
# OLLAMA_MODEL=llama3

# The system will automatically detect which AI providers are configured.
# If both are configured, Ollama will be preferred.
# If only one is configured, that provider will be used automatically.
# The frontend will fetch this configuration from the server via /api/ai-providers endpoint.