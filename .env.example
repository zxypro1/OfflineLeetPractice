# AI Problem Generator Configuration
# Copy this file to .env.local and add your actual API keys

# === DeepSeek Configuration (Optional) ===
# DeepSeek API Key for AI problem generation
# Get your API key from: https://platform.deepseek.com/
# DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Optional: Set DeepSeek model (default: deepseek-chat)
# DEEPSEEK_MODEL=deepseek-chat

# Optional: Set API timeout (default: 30000ms)
# DEEPSEEK_API_TIMEOUT=30000

# Optional: Set maximum tokens for generation (default: 4000)
# DEEPSEEK_MAX_TOKENS=4000

# === OpenAI Configuration (Optional) ===
# OpenAI API Key for AI problem generation
# Get your API key from: https://platform.openai.com/
# OPENAI_API_KEY=your_openai_api_key_here

# Optional: Set OpenAI model (default: gpt-4-turbo)
# OPENAI_MODEL=gpt-4-turbo

# === Qwen (通义千问) Configuration (Optional) ===
# Qwen API Key for AI problem generation
# Get your API key from: https://dashscope.console.aliyun.com/
# QWEN_API_KEY=your_qwen_api_key_here

# Optional: Set Qwen model (default: qwen-turbo)
# QWEN_MODEL=qwen-turbo

# === Claude Configuration (Optional) ===
# Claude API Key for AI problem generation
# Get your API key from: https://console.anthropic.com/
# CLAUDE_API_KEY=your_claude_api_key_here

# Optional: Set Claude model (default: claude-3-haiku-20240307)
# CLAUDE_MODEL=claude-3-haiku-20240307

# === Ollama Configuration (Optional) ===
# Ollama endpoint (default: http://localhost:11434)
# OLLAMA_ENDPOINT=http://localhost:11434

# Ollama model (default: llama3)
# OLLAMA_MODEL=llama3

# The system will automatically detect which AI providers are configured.
# If multiple providers are configured, the system will use them in this order of preference:
# 1. Ollama (local)
# 2. OpenAI
# 3. Claude
# 4. Qwen
# 5. DeepSeek
# You can manually select a provider in the UI if multiple are configured.
# The frontend will fetch this configuration from the server via /api/ai-providers endpoint.